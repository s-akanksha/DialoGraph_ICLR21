{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_58623/4158495153.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'..'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# for utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../..'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# for cocoa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mddict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coding/Dialograph/DialoGraph_ICLR21/src/preproc/../utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mddict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "# This file will be used to prepare the data for the graphical models (or strategy structure predictions)\n",
    "import pickle, pdb\n",
    "import sys\n",
    "sys.path.append('..') # for utils\n",
    "sys.path.append('../..') # for cocoa\n",
    "import utils\n",
    "from collections import defaultdict as ddict\n",
    "import numpy as np\n",
    "from cocoa_folder.cocoa.core.dataset import Example\n",
    "from cocoa_folder.craigslistbargain.parse_dialogue import parse_example\n",
    "from cocoa_folder.craigslistbargain.core.price_tracker import PriceTracker\n",
    "from cocoa_folder.craigslistbargain.model.generator import Templates\n",
    "from cocoa_folder.craigslistbargain.core.scenario import Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_tracker = PriceTracker(utils.PROJ_DIR + \"cocoa_folder/craigslistbargain/price_tracker.pkl\")\n",
    "templates = Templates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_strategies = pickle.load(open(utils.PROJ_DIR + 'data/negotiation_data/data_w_strategies_outcomes.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL has normalize_price = False\n",
    "# FULL_Yiheng has normalize_price = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_price = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_strategies(data_point):\n",
    "    '''\n",
    "    Takes data point and returns list of negotiation strategies, and dialogue acts\n",
    "    '''\n",
    "    utterances = parse_example(Example.from_dict(data_point, Scenario), price_tracker, templates) # Taken from Yiheng's work\n",
    "    utterances = utterances[2:] # skip first two\n",
    "    #agent_list = [x['agent'] for x in data_point['events'] if type(x['data']) == str]\n",
    "    agent_list = [-1]\n",
    "    strategy_list = [['<start>']]    # start + len(events) #  +[x['strategies'] for x in data_point['events'] if type(x['data']) == str]\n",
    "    utterance_list = ['<start>'] # start + len(events)\n",
    "    dial_act_list = ['<start>']    # start + len(events)\n",
    "    last_strat = []\n",
    "    for i, utt in enumerate(utterances):\n",
    "        if utt.text == None:\n",
    "            text = '<' + str(data_point['events'][i]['action']) + '>' # offer, accept, reject, quit\n",
    "            agent = data_point['events'][i]['agent']\n",
    "            dial_act = '<' + utt.lf.to_dict()['intent'] + '>'\n",
    "            if dial_act != '<start>': strats = last_strat             # copy last strategy for end portions\n",
    "            else:                     strats = []\n",
    "        else:\n",
    "            text = utils.normalizeString(utt.text, utt.lf.to_dict(), data_point[\"scenario\"], normalize_price = norm_price)\n",
    "            strats = data_point['events'][i]['strategies']\n",
    "            last_strat = strats\n",
    "            agent = data_point['events'][i]['agent']\n",
    "            dial_act = utt.lf.to_dict()['intent']\n",
    "        utterance_list.append(text)\n",
    "        dial_act_list.append(dial_act)\n",
    "        agent_list.append(agent)\n",
    "        strategy_list.append(strats)\n",
    "    assert len(utterance_list) == len(data_point['events']) + 1, pdb.set_trace()\n",
    "    assert len(utterance_list) == len(strategy_list), pdb.set_trace()\n",
    "    assert len(utterance_list) == len(agent_list), pdb.set_trace()\n",
    "    assert len(utterance_list) == len(dial_act_list), pdb.set_trace()\n",
    "    return agent_list, utterance_list, strategy_list, dial_act_list\n",
    "    \n",
    "#    return [(x['agent'], x['data'], x['strategies']) for x in data_point['events'] if type(x['data']) == str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dtype :  train\n",
      "Dtype :  test\n",
      "Dtype :  dev\n"
     ]
    }
   ],
   "source": [
    "# full_data = [] # list of conversations\n",
    "# for i, data_point in enumerate(train_data):\n",
    "#     agent_list, utterance_list, strategies_list, dial_act_list = get_strategies(data_point)\n",
    "#     ratio = utils.getRatio(data_point)\n",
    "#     full_data.append({'agent_list': agent_list,\n",
    "#                      'utterance': utterance_list,\n",
    "#                      'strategies': strategies_list,\n",
    "#                      'ratio': ratio,\n",
    "#                      'dial_acts': dial_act_list\n",
    "#                      })\n",
    "# print (len(full_data))\n",
    "# print (full_data[76])\n",
    "\n",
    "full_data_all = {}\n",
    "for dtype in data_w_strategies:\n",
    "    print ('Dtype : ', dtype)\n",
    "    data = data_w_strategies[dtype]\n",
    "    full_data_list = []\n",
    "    for i, data_point in enumerate(data):\n",
    "        agent_list, utterance_list, strategies_list, dial_act_list = get_strategies(data_point)\n",
    "        ratio = utils.getRatio(data_point)\n",
    "        uuid  = data_point['uuid']\n",
    "        scene = (data_point[\"scenario\"][\"kbs\"][1][\"item\"][\"Category\"] + \" \" + \" \".join(data_point[\"scenario\"][\"kbs\"][1][\"item\"][\"Description\"])+ \" \" + data_point[\"scenario\"][\"kbs\"][1][\"item\"][\"Title\"])\n",
    "        scene = utils.normalizeString(scene, {\"price\":None}, data_point[\"scenario\"], normalize_price = norm_price) \n",
    "        full_data_list.append({'agent_list': agent_list,\n",
    "                     'utterance': utterance_list,\n",
    "                     'strategies': strategies_list,\n",
    "                     'ratio': ratio,\n",
    "                     'dial_acts': dial_act_list,\n",
    "                     'uuid': uuid,\n",
    "                     'scene': scene,\n",
    "                     'raw_data': data_point\n",
    "                     })\n",
    "    #print (len(full_data_list))\n",
    "    #print (full_data_list[76])\n",
    "    full_data_all[dtype] = full_data_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only use full_data_all from now on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTYPE :  train\n",
      "defaultdict(<class 'int'>, {'<start>': 5383, 'buyer_pos_sentiment': 12710, 'first_person_singular_count_buyer': 14341, 'third_person_singular_buyer': 8122, 'buyer_propose': 5249, 'hedge_count_buyer': 7023, 'assertive_count_buyer': 2044, 'politeness_buyer_greet': 3596, 'first_person_singular_count_seller': 11780, 'third_person_singular_seller': 8878, 'number_of_diff_dic_pos': 18610, 'number_of_diff_dic_neg': 10402, 'personal_concern_seller': 9135, 'liwc_certainty': 2530, 'seller_propose': 3200, 'hedge_count_seller': 5204, 'assertive_count_seller': 2393, 'first_person_plural_count_seller': 1843, 'politeness_seller_greet': 3043, 'factive_count_buyer': 1666, 'factive_count_seller': 1763, 'third_person_plural_buyer': 744, 'seller_neg_sentiment': 2587, 'seller_pos_sentiment': 12152, 'liwc_informal': 2396, 'who_propose': 1009, 'first_person_plural_count_buyer': 1033, 'politeness_seller_gratitude': 1073, 'buyer_neg_sentiment': 1093, 'politeness_seller_please': 60, 'politeness_buyer_gratitude': 2098, 'third_person_plural_seller': 977, 'seller_trade_in': 883, 'politeness_seller_please_s': 77, 'family': 201, 'politeness_buyer_please': 188, 'friend': 149, 'politeness_buyer_please_s': 47})\n",
      "{'assertive_count_buyer', 'third_person_plural_buyer', 'family', 'factive_count_seller', 'politeness_seller_please_s', 'buyer_pos_sentiment', 'first_person_plural_count_seller', 'hedge_count_buyer', 'assertive_count_seller', 'friend', 'third_person_plural_seller', 'third_person_singular_seller', 'factive_count_buyer', 'politeness_buyer_please_s', 'liwc_certainty', '<start>', 'number_of_diff_dic_pos', 'first_person_plural_count_buyer', 'hedge_count_seller', 'seller_propose', 'seller_neg_sentiment', 'politeness_seller_gratitude', 'liwc_informal', 'politeness_seller_please', 'first_person_singular_count_seller', 'seller_trade_in', 'politeness_buyer_please', 'third_person_singular_buyer', 'buyer_neg_sentiment', 'politeness_buyer_greet', 'politeness_seller_greet', 'who_propose', 'buyer_propose', 'politeness_buyer_gratitude', 'first_person_singular_count_buyer', 'number_of_diff_dic_neg', 'seller_pos_sentiment', 'personal_concern_seller'}\n",
      "Total 38 strategies\n",
      "defaultdict(<class 'int'>, {'<start>': 5383, 'init-price': 4828, 'unknown': 9838, 'insist': 474, 'counter-price': 8042, 'agree': 1985, '<offer>': 4657, '<accept>': 4084, 'intro': 4743, 'inquiry': 5224, 'disagree': 2085, 'vague-price': 401, 'inform': 2413, '<quit>': 474, '<reject>': 349})\n",
      "{'inform', 'init-price', 'inquiry', 'disagree', 'counter-price', 'unknown', '<reject>', '<offer>', 'intro', 'vague-price', '<start>', '<accept>', '<quit>', 'insist', 'agree'}\n",
      "Total 15 dial acts\n",
      "DTYPE :  test\n",
      "defaultdict(<class 'int'>, {'<start>': 656, 'buyer_pos_sentiment': 1157, 'seller_pos_sentiment': 1143, 'third_person_singular_seller': 812, 'number_of_diff_dic_pos': 2016, 'first_person_singular_count_buyer': 572, 'third_person_singular_buyer': 893, 'buyer_propose': 613, 'hedge_count_buyer': 710, 'number_of_diff_dic_neg': 1144, 'factive_count_buyer': 193, 'assertive_count_buyer': 217, 'buyer_neg_sentiment': 113, 'politeness_buyer_please': 19, 'politeness_buyer_greet': 66, 'seller_neg_sentiment': 292, 'seller_propose': 347, 'first_person_singular_count_seller': 370, 'politeness_buyer_gratitude': 107, 'personal_concern_seller': 967, 'friend': 17, 'assertive_count_seller': 251, 'third_person_plural_seller': 115, 'who_propose': 119, 'first_person_plural_count_seller': 159, 'hedge_count_seller': 533, 'factive_count_seller': 176, 'liwc_certainty': 254, 'seller_trade_in': 93, 'first_person_plural_count_buyer': 105, 'politeness_seller_gratitude': 62, 'liwc_informal': 85, 'politeness_seller_greet': 59, 'politeness_seller_please': 6, 'third_person_plural_buyer': 85, 'family': 23})\n",
      "{'assertive_count_buyer', 'third_person_plural_buyer', 'family', 'factive_count_seller', 'buyer_pos_sentiment', 'first_person_plural_count_seller', 'hedge_count_buyer', 'assertive_count_seller', 'friend', 'third_person_plural_seller', 'third_person_singular_seller', 'personal_concern_seller', 'factive_count_buyer', 'liwc_certainty', '<start>', 'number_of_diff_dic_pos', 'first_person_plural_count_buyer', 'hedge_count_seller', 'seller_propose', 'seller_neg_sentiment', 'politeness_seller_gratitude', 'liwc_informal', 'politeness_seller_please', 'first_person_singular_count_seller', 'politeness_buyer_please', 'seller_trade_in', 'third_person_singular_buyer', 'buyer_neg_sentiment', 'who_propose', 'politeness_seller_greet', 'buyer_propose', 'politeness_buyer_gratitude', 'first_person_singular_count_buyer', 'number_of_diff_dic_neg', 'seller_pos_sentiment', 'politeness_buyer_greet'}\n",
      "Total 36 strategies\n",
      "defaultdict(<class 'int'>, {'<start>': 656, 'intro': 573, 'unknown': 1155, 'init-price': 561, 'counter-price': 916, 'agree': 217, '<offer>': 546, '<accept>': 474, 'inquiry': 610, 'inform': 274, 'vague-price': 36, '<reject>': 50, 'disagree': 244, 'insist': 48, '<quit>': 67})\n",
      "{'insist', 'inform', 'init-price', 'inquiry', 'disagree', 'unknown', '<reject>', '<offer>', 'intro', 'vague-price', '<start>', '<accept>', '<quit>', 'counter-price', 'agree'}\n",
      "Total 15 dial acts\n",
      "DTYPE :  dev\n",
      "defaultdict(<class 'int'>, {'<start>': 643, 'politeness_buyer_greet': 435, 'seller_pos_sentiment': 1354, 'number_of_diff_dic_pos': 2172, 'seller_neg_sentiment': 318, 'first_person_singular_count_seller': 1346, 'number_of_diff_dic_neg': 1227, 'buyer_neg_sentiment': 144, 'factive_count_buyer': 174, 'third_person_singular_seller': 974, 'hedge_count_seller': 570, 'first_person_singular_count_buyer': 1660, 'third_person_singular_buyer': 984, 'buyer_propose': 609, 'personal_concern_seller': 1053, 'politeness_seller_greet': 364, 'hedge_count_buyer': 838, 'assertive_count_seller': 270, 'buyer_pos_sentiment': 1511, 'liwc_informal': 254, 'first_person_plural_count_buyer': 117, 'first_person_plural_count_seller': 193, 'liwc_certainty': 294, 'seller_propose': 373, 'who_propose': 121, 'politeness_buyer_gratitude': 231, 'third_person_plural_buyer': 90, 'factive_count_seller': 201, 'seller_trade_in': 105, 'assertive_count_buyer': 239, 'third_person_plural_seller': 117, 'politeness_seller_gratitude': 119, 'politeness_seller_please_s': 13, 'politeness_buyer_please': 23, 'politeness_buyer_please_s': 7, 'family': 30, 'politeness_seller_please': 9, 'friend': 18})\n",
      "{'assertive_count_buyer', 'third_person_plural_buyer', 'family', 'factive_count_seller', 'politeness_seller_please_s', 'buyer_pos_sentiment', 'first_person_plural_count_seller', 'hedge_count_buyer', 'assertive_count_seller', 'friend', 'third_person_plural_seller', 'third_person_singular_seller', 'factive_count_buyer', 'politeness_buyer_please_s', 'liwc_certainty', '<start>', 'number_of_diff_dic_pos', 'first_person_plural_count_buyer', 'hedge_count_seller', 'seller_propose', 'seller_neg_sentiment', 'politeness_seller_gratitude', 'liwc_informal', 'politeness_seller_please', 'first_person_singular_count_seller', 'seller_trade_in', 'politeness_buyer_please', 'third_person_singular_buyer', 'buyer_neg_sentiment', 'politeness_buyer_greet', 'politeness_seller_greet', 'who_propose', 'buyer_propose', 'politeness_buyer_gratitude', 'first_person_singular_count_buyer', 'number_of_diff_dic_neg', 'seller_pos_sentiment', 'personal_concern_seller'}\n",
      "Total 38 strategies\n",
      "defaultdict(<class 'int'>, {'<start>': 643, 'intro': 552, 'unknown': 1167, 'disagree': 256, 'init-price': 542, '<offer>': 557, '<accept>': 467, '<reject>': 65, 'inquiry': 625, 'inform': 283, 'counter-price': 945, 'agree': 232, '<quit>': 57, 'vague-price': 54, 'insist': 39})\n",
      "{'insist', 'inform', 'init-price', 'disagree', 'inquiry', 'counter-price', 'unknown', '<offer>', 'intro', 'vague-price', '<start>', '<accept>', '<quit>', '<reject>', 'agree'}\n",
      "Total 15 dial acts\n"
     ]
    }
   ],
   "source": [
    "# See Frequent strategies\n",
    "strategies_freq = {}\n",
    "all_strategies = {}\n",
    "dial_act_freq = {}\n",
    "all_dial_act = {}\n",
    "for dtype in full_data_all:\n",
    "    print ('DTYPE : ', dtype)\n",
    "    data = full_data_all[dtype]\n",
    "    strategies_freq_ = ddict(int)\n",
    "    dial_act_freq_   = ddict(int)\n",
    "    all_strategies_ = set()\n",
    "    all_dial_act_   = set()\n",
    "    for i, data_point in enumerate(data):\n",
    "        for conv in data_point['strategies']:\n",
    "            for strategy in conv:\n",
    "                strategies_freq_[strategy] += 1\n",
    "                all_strategies_.add(strategy)\n",
    "        for da in data_point['dial_acts']:\n",
    "            dial_act_freq_[da] += 1\n",
    "            all_dial_act_.add(da)\n",
    "    print (strategies_freq_)\n",
    "    print (all_strategies_)\n",
    "    print (f'Total {len(all_strategies_)} strategies')\n",
    "    print (dial_act_freq_)\n",
    "    print (all_dial_act_)\n",
    "    print (f'Total {len(all_dial_act_)} dial acts')\n",
    "    strategies_freq[dtype] = strategies_freq_\n",
    "    all_strategies[dtype]  = all_strategies_\n",
    "    dial_act_freq[dtype] = dial_act_freq_\n",
    "    all_dial_act[dtype]  = all_dial_act_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS FEATURE MAP IS USED BY YIHENG\n",
    "recommendation_feature_mapping = {\"seller_neg_sentiment\":0,\"seller_pos_sentiment\":1,\n",
    "                                  \"buyer_neg_sentiment\":2,\"buyer_pos_sentiment\":3,\n",
    "                                  \"first_person_plural_count_seller\":4,\"first_person_singular_count_seller\":5,\n",
    "                                  \"first_person_plural_count_buyer\":6,\"first_person_singular_count_buyer\":7,\n",
    "                                  \"third_person_singular_seller\":8,\"third_person_plural_seller\":9,\n",
    "                                  \"third_person_singular_buyer\":10,\"third_person_plural_buyer\":11,\n",
    "                                  \"number_of_diff_dic_pos\":12,\"number_of_diff_dic_neg\":13,\n",
    "                                  \"buyer_propose\":14,\"seller_propose\":15,\n",
    "                                  \"hedge_count_seller\":16,\"hedge_count_buyer\":17,\n",
    "                                  \"assertive_count_seller\":18,\"assertive_count_buyer\":19,\n",
    "                                  \"factive_count_seller\":20,\"factive_count_buyer\":21,\n",
    "                                  \"who_propose\":22,\"seller_trade_in\":23,\n",
    "                                  \"personal_concern_seller\":24,\"sg_concern\":25,\n",
    "                                  \"liwc_certainty\":26,\"liwc_informal\":27,\n",
    "                                  \"politeness_seller_please\":28,\"politeness_seller_gratitude\":29,\n",
    "                                  \"politeness_seller_please_s\":30,\n",
    "                                  \"ap_des\":31,\"ap_pata\":32,\"ap_infer\":33,\n",
    "                                  \"family\":34,\"friend\":35,\n",
    "                                  \"politeness_buyer_please\":36,\"politeness_buyer_gratitude\":37,\n",
    "                                  \"politeness_buyer_please_s\":38,\n",
    "                                  \"politeness_seller_greet\":39,\"politeness_buyer_greet\":40}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "{'<start>'}\n",
      "{'ap_pata', 'ap_infer', 'sg_concern', 'ap_des'}\n",
      "test\n",
      "{'<start>'}\n",
      "{'politeness_buyer_please_s', 'sg_concern', 'ap_infer', 'politeness_seller_please_s', 'ap_des', 'ap_pata'}\n",
      "dev\n",
      "{'<start>'}\n",
      "{'ap_pata', 'ap_infer', 'sg_concern', 'ap_des'}\n"
     ]
    }
   ],
   "source": [
    "# See what all strategies are there in the feature mapping and not there in all types of data\n",
    "yiheng_strategies = set([k for k in recommendation_feature_mapping])\n",
    "for dtype in all_strategies:\n",
    "    print (dtype)\n",
    "    all_strategies_ = all_strategies[dtype]\n",
    "    print (all_strategies_ - yiheng_strategies)\n",
    "    print (yiheng_strategies - all_strategies_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seller_neg_sentiment': 'neg_sentiment', 'seller_pos_sentiment': 'pos_sentiment', 'buyer_neg_sentiment': 'neg_sentiment', 'buyer_pos_sentiment': 'pos_sentiment', 'first_person_plural_count_seller': 'first_person_plural_count', 'first_person_singular_count_seller': 'first_person_singular_count', 'first_person_plural_count_buyer': 'first_person_plural_count', 'first_person_singular_count_buyer': 'first_person_singular_count', 'third_person_singular_seller': 'third_person_singular', 'third_person_plural_seller': 'third_person_plural', 'third_person_singular_buyer': 'third_person_singular', 'third_person_plural_buyer': 'third_person_plural', 'number_of_diff_dic_pos': 'number_of_diff_dic_pos', 'number_of_diff_dic_neg': 'number_of_diff_dic_neg', 'buyer_propose': 'propose', 'seller_propose': 'propose', 'hedge_count_seller': 'hedge_count', 'hedge_count_buyer': 'hedge_count', 'assertive_count_seller': 'assertive_count', 'assertive_count_buyer': 'assertive_count', 'factive_count_seller': 'factive_count', 'factive_count_buyer': 'factive_count', 'who_propose': 'who_propose', 'seller_trade_in': 'trade_in', 'personal_concern_seller': 'personal_concern', 'sg_concern': 'sg_concern', 'liwc_certainty': 'liwc_certainty', 'liwc_informal': 'liwc_informal', 'politeness_seller_please': 'politeness_please', 'politeness_seller_gratitude': 'politeness_gratitude', 'politeness_seller_please_s': 'politeness_please', 'ap_des': 'ap_des', 'ap_pata': 'ap_pata', 'ap_infer': 'ap_infer', 'family': 'family', 'friend': 'friend', 'politeness_buyer_please': 'politeness_please', 'politeness_buyer_gratitude': 'politeness_gratitude', 'politeness_buyer_please_s': 'politeness_please', 'politeness_seller_greet': 'politeness_greet', 'politeness_buyer_greet': 'politeness_greet'}\n"
     ]
    }
   ],
   "source": [
    "# Map recommendation feature mapping to a uniform_strategy_mapping\n",
    "# This uniform mapping is without sellers or buyers\n",
    "# For exampel : {buyer_propose : propose, seller_propose : propose}\n",
    "recommended2uniform_strategymapping = {}\n",
    "idx = 0\n",
    "for strategy in recommendation_feature_mapping:\n",
    "    new_strategy = strategy.replace('_seller', '').replace('_buyer', '').replace('seller_', '').replace('buyer_', '').replace('please_s', 'please')\n",
    "    recommended2uniform_strategymapping[strategy] = new_strategy\n",
    "print (recommended2uniform_strategymapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended2uniform_strategymapping['<start>'] = '<start>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seller_neg_sentiment': 'neg_sentiment',\n",
       " 'seller_pos_sentiment': 'pos_sentiment',\n",
       " 'buyer_neg_sentiment': 'neg_sentiment',\n",
       " 'buyer_pos_sentiment': 'pos_sentiment',\n",
       " 'first_person_plural_count_seller': 'first_person_plural_count',\n",
       " 'first_person_singular_count_seller': 'first_person_singular_count',\n",
       " 'first_person_plural_count_buyer': 'first_person_plural_count',\n",
       " 'first_person_singular_count_buyer': 'first_person_singular_count',\n",
       " 'third_person_singular_seller': 'third_person_singular',\n",
       " 'third_person_plural_seller': 'third_person_plural',\n",
       " 'third_person_singular_buyer': 'third_person_singular',\n",
       " 'third_person_plural_buyer': 'third_person_plural',\n",
       " 'number_of_diff_dic_pos': 'number_of_diff_dic_pos',\n",
       " 'number_of_diff_dic_neg': 'number_of_diff_dic_neg',\n",
       " 'buyer_propose': 'propose',\n",
       " 'seller_propose': 'propose',\n",
       " 'hedge_count_seller': 'hedge_count',\n",
       " 'hedge_count_buyer': 'hedge_count',\n",
       " 'assertive_count_seller': 'assertive_count',\n",
       " 'assertive_count_buyer': 'assertive_count',\n",
       " 'factive_count_seller': 'factive_count',\n",
       " 'factive_count_buyer': 'factive_count',\n",
       " 'who_propose': 'who_propose',\n",
       " 'seller_trade_in': 'trade_in',\n",
       " 'personal_concern_seller': 'personal_concern',\n",
       " 'sg_concern': 'sg_concern',\n",
       " 'liwc_certainty': 'liwc_certainty',\n",
       " 'liwc_informal': 'liwc_informal',\n",
       " 'politeness_seller_please': 'politeness_please',\n",
       " 'politeness_seller_gratitude': 'politeness_gratitude',\n",
       " 'politeness_seller_please_s': 'politeness_please',\n",
       " 'ap_des': 'ap_des',\n",
       " 'ap_pata': 'ap_pata',\n",
       " 'ap_infer': 'ap_infer',\n",
       " 'family': 'family',\n",
       " 'friend': 'friend',\n",
       " 'politeness_buyer_please': 'politeness_please',\n",
       " 'politeness_buyer_gratitude': 'politeness_gratitude',\n",
       " 'politeness_buyer_please_s': 'politeness_please',\n",
       " 'politeness_seller_greet': 'politeness_greet',\n",
       " 'politeness_buyer_greet': 'politeness_greet',\n",
       " '<start>': '<start>'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended2uniform_strategymapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "# Unique types of uniform_strategies\n",
    "print (len(set([v for k,v in recommended2uniform_strategymapping.items()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip strategies :  ['who_propose', 'ap_pata', 'ap_infer', 'sg_concern', 'ap_des']\n",
      "{'family': 0, 'third_person_plural': 1, 'friend': 2, 'trade_in': 3, 'first_person_plural_count': 4, 'politeness_greet': 5, 'neg_sentiment': 6, 'politeness_gratitude': 7, 'propose': 8, 'hedge_count': 9, '<start>': 10, 'number_of_diff_dic_pos': 11, 'first_person_singular_count': 12, 'assertive_count': 13, 'liwc_informal': 14, 'pos_sentiment': 15, 'personal_concern': 16, 'third_person_singular': 17, 'politeness_please': 18, 'number_of_diff_dic_neg': 19, 'factive_count': 20, 'liwc_certainty': 21}\n"
     ]
    }
   ],
   "source": [
    "uniform_feature_mapping = {}\n",
    "skip_strategies = ['who_propose'] + list(yiheng_strategies - all_strategies['dev'])\n",
    "print ('Skip strategies : ', skip_strategies)\n",
    "uniform_strategies = set([v for k,v in recommended2uniform_strategymapping.items()])\n",
    "idx = 0\n",
    "for i, item in enumerate(uniform_strategies):\n",
    "    if item in skip_strategies:\n",
    "        continue\n",
    "    uniform_feature_mapping[item] = idx\n",
    "    idx += 1\n",
    "print (uniform_feature_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165682\n",
      "   first_person_singular_count 0.1577 26121\n",
      "                 pos_sentiment 0.1501 24862\n",
      "        number_of_diff_dic_pos 0.1123 18610\n",
      "         third_person_singular 0.1026 17000\n",
      "                   hedge_count 0.0738 12227\n",
      "        number_of_diff_dic_neg 0.0628 10402\n",
      "              personal_concern 0.0551 9135\n",
      "                       propose 0.0510 8449\n",
      "              politeness_greet 0.0401 6639\n",
      "                       <start> 0.0325 5383\n",
      "               assertive_count 0.0268 4437\n",
      "                 neg_sentiment 0.0222 3680\n",
      "                 factive_count 0.0207 3429\n",
      "          politeness_gratitude 0.0191 3171\n",
      "     first_person_plural_count 0.0174 2876\n",
      "                liwc_certainty 0.0153 2530\n",
      "                 liwc_informal 0.0145 2396\n",
      "           third_person_plural 0.0104 1721\n",
      "                   who_propose 0.0061 1009\n",
      "                      trade_in 0.0053 883\n",
      "             politeness_please 0.0022 372\n",
      "                        family 0.0012 201\n",
      "                        friend 0.0009 149\n",
      "'Total 22 strategies'\n"
     ]
    }
   ],
   "source": [
    "# See frequency of uniform_strategies\n",
    "strategies_freq = ddict(int)\n",
    "for i, data_point in enumerate(full_data_all['train']):\n",
    "    for conv in data_point['strategies']:\n",
    "        for strategy in conv:\n",
    "#             if strategy == '<start>':\n",
    "#                 uniform_strategy = strategy\n",
    "#             else:\n",
    "            uniform_strategy = recommended2uniform_strategymapping[strategy]\n",
    "            strategies_freq[uniform_strategy] += 1\n",
    "from pprint import pprint\n",
    "#pprint (sorted(strategies_freq.items(), key = lambda x: x[1], reverse = True))\n",
    "tot = np.sum([v for k,v in strategies_freq.items()])\n",
    "print (tot)\n",
    "for k,v in (sorted(strategies_freq.items(), key = lambda x: x[1], reverse = True)):\n",
    "    print (\"%30s %.4f %d\" % (k, v / tot, v))\n",
    "pprint (f'Total {len(strategies_freq)-1} strategies') # -1 for who_propose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54980\n",
      "                       unknown 0.1789 9838\n",
      "                 counter-price 0.1463 8042\n",
      "                       <start> 0.0979 5383\n",
      "                       inquiry 0.0950 5224\n",
      "                    init-price 0.0878 4828\n",
      "                         intro 0.0863 4743\n",
      "                       <offer> 0.0847 4657\n",
      "                      <accept> 0.0743 4084\n",
      "                        inform 0.0439 2413\n",
      "                      disagree 0.0379 2085\n",
      "                         agree 0.0361 1985\n",
      "                        insist 0.0086 474\n",
      "                        <quit> 0.0086 474\n",
      "                   vague-price 0.0073 401\n",
      "                      <reject> 0.0063 349\n",
      "'Total 15 dialogue acts'\n"
     ]
    }
   ],
   "source": [
    "# See frequency of dial_acts\n",
    "da_freq = dial_act_freq['train']\n",
    "from pprint import pprint\n",
    "#pprint (sorted(strategies_freq.items(), key = lambda x: x[1], reverse = True))\n",
    "tot = np.sum([v for k,v in da_freq.items()])\n",
    "print (tot)\n",
    "for k,v in (sorted(da_freq.items(), key = lambda x: x[1], reverse = True)):\n",
    "    print (\"%30s %.4f %d\" % (k, v / tot, v))\n",
    "pprint (f\"Total {len(all_dial_act['train'])} dialogue acts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'family': 0, 'third_person_plural': 1, 'friend': 2, 'trade_in': 3, 'first_person_plural_count': 4, 'politeness_greet': 5, 'neg_sentiment': 6, 'politeness_gratitude': 7, 'propose': 8, 'hedge_count': 9, 'number_of_diff_dic_pos': 10, 'first_person_singular_count': 11, 'assertive_count': 12, 'liwc_informal': 13, 'pos_sentiment': 14, 'personal_concern': 15, 'third_person_singular': 16, 'politeness_please': 17, 'number_of_diff_dic_neg': 18, 'factive_count': 19, 'liwc_certainty': 20, '<start>': 21}\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "chosen_strategies_mapping = {}#{k:v for k,v in uniform_feature_mapping.items() if k != '<start>'}\n",
    "cntr = 0\n",
    "for k,v in uniform_feature_mapping.items():\n",
    "    if k!='<start>':\n",
    "        chosen_strategies_mapping[k] = cntr\n",
    "        cntr += 1\n",
    "chosen_strategies_mapping['<start>'] = len(chosen_strategies_mapping)\n",
    "# skip_strategies = ['who_propose'] + list(yiheng_strategies - all_strategies)\n",
    "# print (\"Skip strategies : \", skip_strategies)\n",
    "# idx = 0\n",
    "# for strategy, mapping in uniform_feature_mapping.items():\n",
    "#     if strategy in skip_strategies:\n",
    "#         continue\n",
    "#     chosen_strategies_mapping[strategy] = idx\n",
    "#     idx += 1\n",
    "print (chosen_strategies_mapping)\n",
    "print (len(chosen_strategies_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inform': 0, 'init-price': 1, 'inquiry': 2, 'disagree': 3, 'counter-price': 4, 'unknown': 5, '<reject>': 6, '<offer>': 7, 'intro': 8, 'vague-price': 9, '<accept>': 10, '<quit>': 11, 'insist': 12, 'agree': 13, '<start>': 14}\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "chosen_dial_act_mapping = {}#{k:i for i, k in enumerate(all_dial_act['train']) if k != '<start>' }\n",
    "cntr = 0\n",
    "for k,v in enumerate(all_dial_act['train']):\n",
    "    if v != '<start>':\n",
    "        chosen_dial_act_mapping[v] = cntr\n",
    "        cntr += 1\n",
    "chosen_dial_act_mapping['<start>'] = len(chosen_dial_act_mapping)\n",
    "print (chosen_dial_act_mapping)\n",
    "print (len(chosen_dial_act_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ap_pata, ap_des, ap_infer and sg_concern are strategies that are learned using the classifiers. \n",
    "# Yiheng did not have any way to extract these for the data from the code he had access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "[(0, 3062), (1, 13552), (2, 10047), (3, 8840), (4, 7222), (5, 5025), (6, 3329), (7, 1958), (8, 1116), (9, 511), (10, 236), (11, 61), (12, 17), (13, 4)]\n",
      "Mean strategies per utt :  2.9951436886140415\n",
      "test\n",
      "[(0, 1059), (1, 1839), (2, 1160), (3, 892), (4, 635), (5, 367), (6, 251), (7, 134), (8, 49), (9, 29), (10, 9), (11, 3)]\n",
      "Mean strategies per utt :  2.2452154971215186\n",
      "dev\n",
      "[(0, 409), (1, 1646), (2, 1159), (3, 1031), (4, 845), (5, 578), (6, 356), (7, 223), (8, 143), (9, 51), (10, 26), (11, 12), (12, 5)]\n",
      "Mean strategies per utt :  2.942473781616286\n"
     ]
    }
   ],
   "source": [
    "# See # of strategies per utterance frequency to see distribution\n",
    "for dtype in full_data_all:\n",
    "    print (dtype)\n",
    "    strategies_perutt_freq = ddict(int)\n",
    "    for i, data_point in enumerate(full_data_all[dtype]):\n",
    "        for conv in data_point['strategies']:\n",
    "            num = len([c for c in conv if recommended2uniform_strategymapping[c] in chosen_strategies_mapping])\n",
    "            strategies_perutt_freq[num] += 1\n",
    "    print (sorted(strategies_perutt_freq.items(), key = lambda x: x))\n",
    "    tot = np.sum([v for k,v in strategies_perutt_freq.items()])\n",
    "    mean_strategies_per_turn = np.sum([k*v for k,v in strategies_perutt_freq.items()]) / tot\n",
    "    print ('Mean strategies per utt : ', mean_strategies_per_turn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Max turns are 47\n",
      "Avg turns are 10.213635519227196\n",
      "[(3, 246), (4, 309), (5, 182), (6, 178), (7, 247), (8, 471), (9, 511), (10, 677), (11, 585), (12, 623), (13, 414), (14, 333), (15, 211), (16, 137), (17, 100), (18, 49), (19, 46), (20, 25), (21, 19), (22, 10), (23, 4), (24, 1), (25, 1), (26, 1), (30, 1), (31, 1), (47, 1)]\n",
      "test\n",
      "Max turns are 24\n",
      "Avg turns are 9.797256097560975\n",
      "[(3, 44), (4, 45), (5, 35), (6, 22), (7, 24), (8, 63), (9, 58), (10, 66), (11, 77), (12, 63), (13, 51), (14, 39), (15, 23), (16, 23), (17, 9), (18, 5), (19, 3), (20, 3), (21, 1), (24, 2)]\n",
      "dev\n",
      "Max turns are 28\n",
      "Avg turns are 10.08398133748056\n",
      "[(3, 35), (4, 47), (5, 21), (6, 24), (7, 25), (8, 65), (9, 57), (10, 66), (11, 66), (12, 64), (13, 48), (14, 53), (15, 21), (16, 21), (17, 10), (18, 9), (19, 6), (20, 1), (21, 1), (23, 1), (25, 1), (28, 1)]\n"
     ]
    }
   ],
   "source": [
    "# See max and avg turns\n",
    "for dtype in full_data_all:\n",
    "    print (dtype)\n",
    "    max_turns = 0\n",
    "    avg_turns = 0\n",
    "    turns_freq = ddict(int)\n",
    "    for i, data_point in enumerate(full_data_all[dtype]):\n",
    "        turns = len(data_point['strategies'])\n",
    "        max_turns = max(max_turns, turns)\n",
    "        avg_turns += turns\n",
    "        turns_freq[turns] += 1\n",
    "    avg_turns /= len(full_data_all[dtype])\n",
    "    print (f'Max turns are {max_turns}')\n",
    "    print (f'Avg turns are {avg_turns}')\n",
    "    print (sorted(turns_freq.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorify full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data into vector form\n",
    "def convert_2dlistofstrategies2vector(strategies, agent_list):\n",
    "    '''\n",
    "    Takes a list of list of strategies and returns numpy arr 2d numpy arr : conv_len x num_strats\n",
    "    '''\n",
    "    strats = np.zeros((len(strategies), len(chosen_strategies_mapping) + 1)) # 1 for agent\n",
    "    for i, stlist in enumerate(strategies):\n",
    "        for st in stlist:\n",
    "            uniform_st = recommended2uniform_strategymapping[st]\n",
    "            if uniform_st not in chosen_strategies_mapping:\n",
    "                continue\n",
    "            strats[i][chosen_strategies_mapping[uniform_st] + 1] = 1    # 1 for leaving space for ageent\n",
    "        try:\n",
    "            if agent_list[i] != -1:\n",
    "                strats[i][0] = agent_list[i]\n",
    "        except:\n",
    "            pdb.set_trace()\n",
    "    return np.array(strats)\n",
    "\n",
    "# for i, data_point in enumerate(full_data):\n",
    "#     full_data[i]['strategies_vec'] = convert_2dlistofstrategies2vector(full_data[i]['strategies'], full_data[i]['agent_list'])\n",
    "# print (full_data[1234])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "test\n",
      "dev\n"
     ]
    }
   ],
   "source": [
    "for dtype in full_data_all:\n",
    "    print (dtype)\n",
    "    data = full_data_all[dtype]\n",
    "    for i in range(len(data)):\n",
    "        data[i]['strategies_vec'] = convert_2dlistofstrategies2vector(data[i]['strategies'], data[i]['agent_list'])\n",
    "        data[i]['dial_acts_vec']   = np.array([chosen_dial_act_mapping[d] for d in data[i]['dial_acts']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 23)\n",
      "(22,)\n"
     ]
    }
   ],
   "source": [
    "print (full_data_all['train'][1234]['strategies_vec'].shape)\n",
    "print (full_data_all['train'][1234]['dial_acts_vec'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_id': 0, 'family': 1, 'third_person_plural': 2, 'friend': 3, 'trade_in': 4, 'first_person_plural_count': 5, 'politeness_greet': 6, 'neg_sentiment': 7, 'politeness_gratitude': 8, 'propose': 9, 'hedge_count': 10, 'number_of_diff_dic_pos': 11, 'first_person_singular_count': 12, 'assertive_count': 13, 'liwc_informal': 14, 'pos_sentiment': 15, 'personal_concern': 16, 'third_person_singular': 17, 'politeness_please': 18, 'number_of_diff_dic_neg': 19, 'factive_count': 20, 'liwc_certainty': 21, '<start>': 22}\n",
      "{0: 'agent_id', 1: 'family', 2: 'third_person_plural', 3: 'friend', 4: 'trade_in', 5: 'first_person_plural_count', 6: 'politeness_greet', 7: 'neg_sentiment', 8: 'politeness_gratitude', 9: 'propose', 10: 'hedge_count', 11: 'number_of_diff_dic_pos', 12: 'first_person_singular_count', 13: 'assertive_count', 14: 'liwc_informal', 15: 'pos_sentiment', 16: 'personal_concern', 17: 'third_person_singular', 18: 'politeness_please', 19: 'number_of_diff_dic_neg', 20: 'factive_count', 21: 'liwc_certainty', 22: '<start>'}\n"
     ]
    }
   ],
   "source": [
    "strategies2colid = {}\n",
    "strategies2colid['agent_id'] = 0\n",
    "for s, idx in chosen_strategies_mapping.items():\n",
    "    strategies2colid[s] = idx+1 # for agent\n",
    "print (strategies2colid)\n",
    "colid2strategies = {v:k for k,v in strategies2colid.items()}\n",
    "print (colid2strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Originally had :  5383\n",
      "Taken          :  4828\n",
      "test\n",
      "Originally had :  656\n",
      "Taken          :  567\n",
      "dev\n",
      "Originally had :  643\n",
      "Taken          :  561\n"
     ]
    }
   ],
   "source": [
    "# Choose data based on certain characteristics\n",
    "# Drop conversations with < 4 utterances\n",
    "taken_data_all = {}\n",
    "for dtype in full_data_all:\n",
    "    print (dtype)\n",
    "    taken_data = []\n",
    "    for i in range(len(full_data_all[dtype])):\n",
    "        if len(full_data_all[dtype][i]['utterance']) <= 4:\n",
    "            continue\n",
    "        taken_data.append(full_data_all[dtype][i])\n",
    "    print ('Originally had : ', len(full_data_all[dtype]))\n",
    "    print ('Taken          : ', len(taken_data))\n",
    "    taken_data_all[dtype] = taken_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_vector_data = {'train': taken_data_all['train'], \n",
    "                        'strategies2colid': strategies2colid, \n",
    "                        'dialacts2id': chosen_dial_act_mapping,\n",
    "                        'test': taken_data_all['test'],\n",
    "                        'valid' : taken_data_all['dev'],}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total conversations in data and zeros among them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total conv are 67891. Out of that 3060 or 0.04507224816249576 are zero vectors.\n"
     ]
    }
   ],
   "source": [
    "total_conv = 0\n",
    "zero_strategy_conv = 0\n",
    "all_data_concatenated = full_data_all['train'] + full_data_all['test'] + full_data_all['dev'] \n",
    "for i in range(len(all_data_concatenated)):\n",
    "    total_conv += all_data_concatenated[i]['strategies_vec'].shape[0]\n",
    "    for j in range(all_data_concatenated[i]['strategies_vec'].shape[0]):\n",
    "        if all(all_data_concatenated[i]['strategies_vec'][j] == 0):\n",
    "            zero_strategy_conv += 1\n",
    "print (f'Total conv are {total_conv}. Out of that {zero_strategy_conv} or {zero_strategy_conv / total_conv} are zero vectors.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Predict everyone as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Total is 1219138. Out of that 184512.0 are 1. Majority class would be : 0.8486537209077233.\n",
      "test\n",
      "Total is 140645. Out of that 16759.0 are 1. Majority class would be : 0.8808418358277934.\n",
      "dev\n",
      "Total is 142393. Out of that 21380.0 are 1. Majority class would be : 0.8498521696993532.\n"
     ]
    }
   ],
   "source": [
    "for dtype in taken_data_all:\n",
    "    print (dtype)\n",
    "    total = 0\n",
    "    ones = 0\n",
    "    for i in range(len(taken_data_all[dtype])):\n",
    "        temp = taken_data_all[dtype][i]['strategies_vec'].reshape(-1)\n",
    "        total += len(temp)\n",
    "        ones  += np.sum(temp)\n",
    "    print (f'Total is {total}. Out of that {ones} are 1. Majority class would be : {(total-ones)/total}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class weights (based on only training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x7f10e6be9dd0>, {0: defaultdict(<class 'int'>, {1: 23908.0, 0: 29098.0}), 1: defaultdict(<class 'int'>, {1: 197.0, 0: 52809.0}), 2: defaultdict(<class 'int'>, {1: 1691.0, 0: 51315.0}), 3: defaultdict(<class 'int'>, {1: 146.0, 0: 52860.0}), 4: defaultdict(<class 'int'>, {1: 877.0, 0: 52129.0}), 5: defaultdict(<class 'int'>, {1: 2842.0, 0: 50164.0}), 6: defaultdict(<class 'int'>, {1: 6036.0, 0: 46970.0}), 7: defaultdict(<class 'int'>, {1: 3618.0, 0: 49388.0}), 8: defaultdict(<class 'int'>, {1: 3155.0, 0: 49851.0}), 9: defaultdict(<class 'int'>, {1: 8333.0, 0: 44673.0}), 10: defaultdict(<class 'int'>, {1: 11995.0, 0: 41011.0}), 11: defaultdict(<class 'int'>, {1: 18178.0, 0: 34828.0}), 12: defaultdict(<class 'int'>, {1: 25496.0, 0: 27510.0}), 13: defaultdict(<class 'int'>, {1: 4384.0, 0: 48622.0}), 14: defaultdict(<class 'int'>, {1: 2374.0, 0: 50632.0}), 15: defaultdict(<class 'int'>, {1: 24464.0, 0: 28542.0}), 16: defaultdict(<class 'int'>, {1: 8910.0, 0: 44096.0}), 17: defaultdict(<class 'int'>, {1: 16676.0, 0: 36330.0}), 18: defaultdict(<class 'int'>, {1: 357.0, 0: 52649.0}), 19: defaultdict(<class 'int'>, {1: 10191.0, 0: 42815.0}), 20: defaultdict(<class 'int'>, {1: 3370.0, 0: 49636.0}), 21: defaultdict(<class 'int'>, {1: 2486.0, 0: 50520.0}), 22: defaultdict(<class 'int'>, {1: 4828.0, 0: 48178.0})})\n"
     ]
    }
   ],
   "source": [
    "# num_zeros / num_ones for each class\n",
    "# sanity is that first class is 50/50\n",
    "num_feats = taken_data_all['train'][0]['strategies_vec'].shape[1]\n",
    "feat_freq = ddict(lambda : ddict(int))\n",
    "for i in range(len(taken_data_all['train'])):\n",
    "    vec = taken_data_all['train'][i]['strategies_vec']\n",
    "    for j in range(num_feats):\n",
    "        ones = np.sum(vec[:, j])\n",
    "        zeros = vec.shape[0] - ones\n",
    "        feat_freq[j][1] += ones\n",
    "        feat_freq[j][0] += zeros\n",
    "print (feat_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.2170821482349004, 1: 268.06598984771574, 2: 30.34594914251922, 3: 362.05479452054794, 4: 59.440136830102624, 5: 17.65095003518649, 6: 7.781643472498343, 7: 13.650635710337204, 8: 15.800633914421553, 9: 5.360974438977559, 10: 3.4190079199666528, 11: 1.9159423478930575, 12: 1.0789927831816755, 13: 11.090784671532846, 14: 21.32771693344566, 15: 1.166693917593198, 16: 4.949046015712683, 17: 2.1785799952026865, 18: 147.47619047619048, 19: 4.201256010205083, 20: 14.728783382789317, 21: 20.321802091713597, 22: 9.97887323943662}\n"
     ]
    }
   ],
   "source": [
    "feature_weights = {}\n",
    "for featid, freq in feat_freq.items():\n",
    "    ones = freq[1]\n",
    "    zeros = freq[0]\n",
    "    weight = zeros / ones\n",
    "    feature_weights[featid] = weight\n",
    "print (feature_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_vector_data['feature_weights'] = feature_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_dial_acts = len(taken_data_all['dialacts2id'])\n",
    "# da_freq = ddict(lambda: ddict(int)) # create again for chosen data\n",
    "# for i in range(len(taken_data_all['train'])):\n",
    "#     vec = taken_data_all['train'][i]['dial_acts_vec']\n",
    "\n",
    "## NO NEED TO CREATE FEATURE WEIGHTS FOR DIAL ACTS. MY TRAINER WILL DO IT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(strategy_vector_data, open('../../data/negotiation_data/strategy_vector_data.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump WFST DATA (seq of bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dtype in ['train', 'valid', 'test']:\n",
    "    f = open(f'../wfst/finite_state_machine/seq_bag_strats_rj_{dtype}', 'w')\n",
    "    for dat in strategy_vector_data[dtype]:\n",
    "        for uttidx, svec in enumerate(dat['strategies_vec']):\n",
    "            f.write('<'+''.join([str(int(ch)) for ch in svec[1:]])+'> ')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump WFST DATA (end form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dtype in ['train', 'valid', 'test']:\n",
    "    f = open(f'../wfst/finite_state_machine/seq_end_strats_rj_{dtype}', 'w')\n",
    "    for dat in strategy_vector_data[dtype]:\n",
    "        for uttidx, svec in enumerate(dat['strategies_vec']):\n",
    "            for colidx, ch in enumerate(svec[1:]):\n",
    "                if ch == 0: continue\n",
    "                strat = colid2strategies[colidx+1]\n",
    "                f.write('<'+strat+'> ')\n",
    "            f.write('<end> ')       # end of utt\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump WFST DATA (Dialogue Acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dtype in ['train', 'valid', 'test']:\n",
    "    f = open(f'../wfst/finite_state_machine/seq_da_acts_rj_{dtype}', 'w')\n",
    "    for dat in strategy_vector_data[dtype]:\n",
    "        for uttidx, dial_act in enumerate(dat['dial_acts']):\n",
    "            f.write('<'+dial_act+'> ')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy Vector Data with WORD IDS\n",
    "\n",
    "## Have to bert ids, word ids (based on some pretrained embedding - see yiheng's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17418c3da7848cfaa4b72582ac8a836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = full_data_all.keys()\n",
    "word2id =  {\"[PAD]\": 0, \"<start>\":1,\"[CLS]\":2,\"[SEP]\":3,\"<offer>\":4,\"<reject>\":5,\"<accept>\":6,\"<quit>\":7,\"[UNK]\":8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size :  13119\n"
     ]
    }
   ],
   "source": [
    "# Set vocab using all training data\n",
    "total = len(word2id) # curr count\n",
    "for k, datapoint in enumerate(data_w_strategies['train']):\n",
    "    print (f'{k}/{len(data_w_strategies[\"train\"])}', end = '\\r')\n",
    "    scene = (datapoint[\"scenario\"][\"kbs\"][1][\"item\"][\"Category\"] + \" \" + \" \".join(datapoint[\"scenario\"][\"kbs\"][1][\"item\"][\"Description\"])+ \" \" + datapoint[\"scenario\"][\"kbs\"][1][\"item\"][\"Title\"])\n",
    "    scene = utils.normalizeString(scene, {\"price\":None}, datapoint[\"scenario\"], normalize_price=norm_price) \n",
    "    for word in scene.split():\n",
    "        if word not in word2id:\n",
    "            word2id[word] = total\n",
    "            total += 1\n",
    "            \n",
    "    utterances = parse_example(Example.from_dict(datapoint, Scenario), price_tracker, templates)[2:]\n",
    "    for i, uter in enumerate(datapoint['events']):\n",
    "        if uter['action'] != 'message': continue\n",
    "        tmp_dict = utterances[i]\n",
    "        for word in utils.normalizeString(uter[\"data\"], tmp_dict.lf.to_dict(), datapoint[\"scenario\"], normalize_price=norm_price).split():\n",
    "            if word not in word2id:\n",
    "                word2id[word] = total\n",
    "                total += 1\n",
    "print(\"Vocab size : \", len(word2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_vector_data['word2id'] = word2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'strategies2colid', 'dialacts2id', 'test', 'valid', 'feature_weights', 'word2id'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategy_vector_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train\n",
      "4827/4828\n",
      "test\n",
      "566/567\n",
      "dev\n",
      "560/561\r"
     ]
    }
   ],
   "source": [
    "cls_token_id = tokenizer.convert_tokens_to_ids(tokenizer.tokenize('[CLS]'))\n",
    "sep_token_id = tokenizer.convert_tokens_to_ids(tokenizer.tokenize('[SEP]'))\n",
    "for dtype in dtypes:\n",
    "    print ()\n",
    "    print (dtype)\n",
    "    if dtype == 'dev': dtype = 'valid'\n",
    "    for i, datapoint in enumerate(strategy_vector_data[dtype]):\n",
    "        print (f'{i}/{len(strategy_vector_data[dtype])}', end = '\\r')\n",
    "        toks_space = [[word2id['[CLS]']] + [word2id.get(w, word2id['[UNK]']) for w in utt.split(' ')] + [word2id['[SEP]']] for utt in datapoint['utterance']]\n",
    "        toks_bert  = [cls_token_id + tokenizer.convert_tokens_to_ids(tokenizer.tokenize(utt)) + sep_token_id for utt in datapoint['utterance']]\n",
    "        scene_space = [word2id.get(w, word2id['[UNK]']) for w in datapoint['scene'].split(' ')]\n",
    "        scene_bert  = cls_token_id + tokenizer.convert_tokens_to_ids(tokenizer.tokenize(datapoint['scene'])) + sep_token_id\n",
    "        datapoint['toks_space'] = toks_space\n",
    "        datapoint['toks_bert']  = toks_bert\n",
    "        datapoint['scene_space'] = scene_space\n",
    "        datapoint['scene_bert'] = scene_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356\n"
     ]
    }
   ],
   "source": [
    "# Max scene seq\n",
    "max_scene_seq = 0\n",
    "for dtype in dtypes:\n",
    "    if dtype == 'dev': dtype = 'valid'\n",
    "    for datapoint in strategy_vector_data[dtype]:\n",
    "        max_scene_seq = max(max_scene_seq, len(datapoint['scene_bert']))\n",
    "print (max_scene_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add ratio bucket (obtained from only train data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4828\n"
     ]
    }
   ],
   "source": [
    "all_ratios = []\n",
    "for datapoint in strategy_vector_data['train']:\n",
    "    all_ratios.append(datapoint['ratio'])\n",
    "print (len(all_ratios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-99999 -0.2\n",
      "-0.2 0.16666666666666666\n",
      "0.16666666666666666 0.4\n",
      "0.4 0.6052631578947368\n",
      "0.6052631578947368 254.8139534883721\n"
     ]
    }
   ],
   "source": [
    "# Split into 5\n",
    "all_ratios = sorted(all_ratios)\n",
    "bucket_size = int(len(all_ratios) * 0.2)\n",
    "bucket1 = all_ratios[              : 1*bucket_size]\n",
    "bucket2 = all_ratios[1*bucket_size : 2*bucket_size]\n",
    "bucket3 = all_ratios[2*bucket_size : 3*bucket_size]\n",
    "bucket4 = all_ratios[3*bucket_size : 4*bucket_size]\n",
    "bucket5 = all_ratios[4*bucket_size :              ]\n",
    "print (min(bucket1), max(bucket1))\n",
    "print (min(bucket2), max(bucket2))\n",
    "print (min(bucket3), max(bucket3))\n",
    "print (min(bucket4), max(bucket4))\n",
    "print (min(bucket5), max(bucket5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "test\n",
      "dev\n",
      "{'agent_list': [-1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0], 'utterance': ['<start>', 'i would love to buy', 'sure ! what s your price ?', 'im on a budget so i could do <price>_-0.1', 'how about <price>_-0.0 and i ll wave the deposit .', 'i will take it', 'great !', '<offer>', '<offer>', '<accept>', '<accept>'], 'strategies': [['<start>'], ['buyer_pos_sentiment', 'first_person_singular_count_buyer', 'hedge_count_buyer'], ['seller_pos_sentiment', 'number_of_diff_dic_neg', 'assertive_count_seller', 'personal_concern_seller'], ['first_person_singular_count_buyer', 'buyer_propose', 'hedge_count_buyer'], ['first_person_singular_count_seller', 'number_of_diff_dic_neg', 'hedge_count_seller', 'personal_concern_seller'], ['first_person_singular_count_buyer', 'third_person_singular_buyer'], ['seller_pos_sentiment'], ['seller_pos_sentiment'], ['seller_pos_sentiment'], ['seller_pos_sentiment'], ['seller_pos_sentiment']], 'ratio': 0.037037037037037035, 'dial_acts': ['<start>', 'intro', 'inquiry', 'init-price', 'counter-price', 'unknown', 'agree', '<offer>', '<offer>', '<accept>', '<accept>'], 'uuid': 'C_f82ff19f74094889873c8acc58ee582f', 'scene': 'housing this is a single family house in an excellent condition . it will be available for move in on july . it s in a very nice and quiet community with great school district . email me for viewing or further information . thanks . huge living room and family room plus spacious bedrooms generous bathrooms with bathtubs great school district oliveira elementary thornton junior high american high few mins drive to bart and lucky and supermarkets spacious two car garage easy access to fwy and dumbarton bridge . deposit one month rent lease one year minimum longer preferred no pet or smoking . no section . no sub leasing . tenant pay all utilities . gardening is included in the rent a bedroom single family house for rent in central fremont', 'raw_data': {'uuid': 'C_f82ff19f74094889873c8acc58ee582f', 'scenario': {'category': 'housing', 'uuid': 'S_Jrg93XX4AYzY9IQ7', 'post_id': '6131652108', 'kbs': [{'personal': {'Bottomline': None, 'Role': 'buyer', 'Target': 1920}, 'item': {'Category': 'housing', 'Images': [], 'Price': 3200, 'Description': [\"This is a single family house in an excellent condition. It will be available for move-in on July 2017. It's in a very nice and quiet community with great school district. Email me for viewing or further information. Thanks.\", 'Huge living room and family room, plus 4 spacious bedrooms', '2 generous bathrooms with bathtubs', 'Great school district (Oliveira elementary, Thornton junior high, American high)', 'Few mins drive to Bart and Lucky and 99 Supermarkets'], 'Title': 'A 4 bedroom single family house for rent in central Fremont'}}, {'personal': {'Bottomline': None, 'Role': 'seller', 'Target': 3200}, 'item': {'Category': 'housing', 'Images': [], 'Price': 3200, 'Description': [\"This is a single family house in an excellent condition. It will be available for move-in on July 2017. It's in a very nice and quiet community with great school district. Email me for viewing or further information. Thanks.\", 'Huge living room and family room, plus 4 spacious bedrooms', '2 generous bathrooms with bathtubs', 'Great school district (Oliveira elementary, Thornton junior high, American high)', 'Few mins drive to Bart and Lucky and 99 Supermarkets', 'Spacious two-car garage', 'Easy access to FWY 880 and Dumbarton Bridge.', 'Deposit: one month rent', 'Lease: one year minimum, longer preferred', 'No pet or smoking. No section 8. No sub-leasing.', 'Tenant pay all utilities. Gardening is included in the rent'], 'Title': 'A 4 bedroom single family house for rent in central Fremont'}}], 'attributes': [{'entity': False, 'unique': False, 'value_type': 'role', 'multivalued': False, 'name': 'Role'}, {'entity': False, 'unique': False, 'value_type': 'price', 'multivalued': False, 'name': 'Bottomline'}, {'entity': False, 'unique': False, 'value_type': 'price', 'multivalued': False, 'name': 'Target'}, {'entity': False, 'unique': False, 'value_type': 'text', 'multivalued': False, 'name': 'Title'}, {'entity': False, 'unique': False, 'value_type': 'text', 'multivalued': False, 'name': 'Category'}, {'entity': False, 'unique': False, 'value_type': 'price', 'multivalued': False, 'name': 'Price'}, {'entity': False, 'unique': False, 'value_type': 'text', 'multivalued': False, 'name': 'Images'}, {'entity': False, 'unique': False, 'value_type': 'text', 'multivalued': False, 'name': 'Description'}], 'intersection': 1.0}, 'scenario_uuid': 'S_vjAzVfmyolx9HnUe', 'agents': {'1': 'human', '0': 'human'}, 'outcome': {'reward': 1, 'offer': {'price': 1900.0, 'sides': ''}, 'buyer_start_amt': 1850.0, 'seller_suggested_amt': 3200, 'accepted_amt': 1900.0}, 'events': [{'action': 'message', 'start_time': '1496341329.09', 'data': 'i would love to buy ', 'agent': 0, 'time': '1496341331.9', 'strategies': ['buyer_pos_sentiment', 'first_person_singular_count_buyer', 'hedge_count_buyer']}, {'action': 'message', 'start_time': '1496341336.5', 'data': \"sure! what's your price?\", 'agent': 1, 'time': '1496341357.74', 'strategies': ['seller_pos_sentiment', 'number_of_diff_dic_neg', 'assertive_count_seller', 'personal_concern_seller']}, {'action': 'message', 'start_time': '1496341369.21', 'data': 'im on a budget so i could do 1850', 'agent': 0, 'time': '1496341377.98', 'strategies': ['first_person_singular_count_buyer', 'buyer_propose', 'hedge_count_buyer']}, {'action': 'message', 'start_time': '1496341419.92', 'data': \"how about $1900 and i'll wave the deposit.\", 'agent': 1, 'time': '1496341433.02', 'strategies': ['first_person_singular_count_seller', 'number_of_diff_dic_neg', 'hedge_count_seller', 'personal_concern_seller']}, {'action': 'message', 'start_time': '1496341447.57', 'data': 'i will take it', 'agent': 0, 'time': '1496341449.28', 'strategies': ['first_person_singular_count_buyer', 'third_person_singular_buyer']}, {'action': 'message', 'start_time': '1496341453.2', 'data': 'great!', 'agent': 1, 'time': '1496341454.29', 'strategies': ['seller_pos_sentiment']}, {'action': 'offer', 'start_time': None, 'data': {'price': 1900.0, 'sides': ''}, 'agent': 1, 'time': '1496341458.26', 'strategies': []}, {'action': 'offer', 'start_time': None, 'data': {'price': 1900.0, 'sides': ''}, 'agent': 0, 'time': '1496341458.58', 'strategies': []}, {'action': 'accept', 'start_time': None, 'data': None, 'agent': 1, 'time': '1496341462.53', 'strategies': []}, {'action': 'accept', 'start_time': None, 'data': None, 'agent': 0, 'time': '1496341464.61', 'strategies': []}]}, 'strategies_vec': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0.]]), 'dial_acts_vec': array([14,  8,  2,  1,  4,  5, 13,  7,  7, 10, 10]), 'toks_space': [[2, 1, 3], [2, 94, 84, 277, 29, 103, 3], [2, 82, 169, 173, 192, 46, 278, 92, 3], [2, 279, 14, 98, 280, 281, 94, 182, 170, 282, 3], [2, 111, 112, 283, 55, 94, 117, 284, 15, 255, 17, 3], [2, 94, 93, 285, 89, 3], [2, 162, 169, 3], [2, 4, 3], [2, 4, 3], [2, 6, 3], [2, 6, 3]], 'toks_bert': [[101, 1026, 2707, 1028, 102], [101, 1045, 2052, 2293, 2000, 4965, 102], [101, 2469, 999, 2054, 1055, 2115, 3976, 1029, 102], [101, 10047, 2006, 1037, 5166, 2061, 1045, 2071, 2079, 1026, 3976, 1028, 1035, 1011, 1014, 1012, 1015, 102], [101, 2129, 2055, 1026, 3976, 1028, 1035, 1011, 1014, 1012, 1014, 1998, 1045, 2222, 4400, 1996, 12816, 1012, 102], [101, 1045, 2097, 2202, 2009, 102], [101, 2307, 999, 102], [101, 1026, 3749, 1028, 102], [101, 1026, 3749, 1028, 102], [101, 1026, 5138, 1028, 102], [101, 1026, 5138, 1028, 102]], 'scene_space': [209, 18, 70, 98, 210, 211, 212, 42, 22, 213, 214, 17, 89, 93, 183, 215, 60, 216, 42, 14, 217, 17, 89, 192, 42, 98, 218, 180, 55, 219, 220, 21, 162, 221, 222, 17, 223, 90, 60, 224, 139, 225, 226, 17, 227, 17, 228, 229, 230, 55, 211, 230, 231, 232, 233, 234, 235, 21, 236, 162, 221, 222, 237, 238, 239, 240, 241, 242, 241, 243, 244, 245, 29, 246, 55, 247, 55, 248, 232, 11, 76, 249, 250, 251, 29, 252, 55, 253, 254, 17, 255, 256, 257, 258, 259, 256, 260, 261, 262, 263, 39, 264, 139, 265, 17, 39, 266, 17, 39, 267, 268, 17, 269, 270, 137, 271, 17, 272, 70, 273, 42, 15, 258, 98, 274, 210, 211, 212, 60, 258, 42, 275, 276], 'scene_bert': [101, 3847, 2023, 2003, 1037, 2309, 2155, 2160, 1999, 2019, 6581, 4650, 1012, 2009, 2097, 2022, 2800, 2005, 2693, 1999, 2006, 2251, 1012, 2009, 1055, 1999, 1037, 2200, 3835, 1998, 4251, 2451, 2007, 2307, 2082, 2212, 1012, 10373, 2033, 2005, 10523, 2030, 2582, 2592, 1012, 4283, 1012, 4121, 2542, 2282, 1998, 2155, 2282, 4606, 22445, 18390, 12382, 28942, 2007, 7198, 28251, 2015, 2307, 2082, 2212, 24263, 4732, 14630, 3502, 2152, 2137, 2152, 2261, 8117, 2015, 3298, 2000, 12075, 1998, 5341, 1998, 26676, 22445, 2048, 2482, 7381, 3733, 3229, 2000, 1042, 18418, 1998, 12873, 8445, 2239, 2958, 1012, 12816, 2028, 3204, 9278, 10084, 2028, 2095, 6263, 2936, 6871, 2053, 9004, 2030, 9422, 1012, 2053, 2930, 1012, 2053, 4942, 26707, 1012, 16713, 3477, 2035, 16548, 1012, 21529, 2003, 2443, 1999, 1996, 9278, 1037, 5010, 2309, 2155, 2160, 2005, 9278, 1999, 2430, 22550, 102], 'ratio_bucket': 1}\n"
     ]
    }
   ],
   "source": [
    "for dtype in dtypes:\n",
    "    print (dtype)\n",
    "    if dtype == 'dev': dtype = 'valid'\n",
    "    for datapoint in strategy_vector_data[dtype]:\n",
    "        ratio = datapoint['ratio']\n",
    "        if   ratio <= max(bucket1): bucket = 0\n",
    "        elif ratio <= max(bucket2): bucket = 1\n",
    "        elif ratio <= max(bucket3): bucket = 2\n",
    "        elif ratio <= max(bucket4): bucket = 3\n",
    "        else:                       bucket = 4\n",
    "        datapoint['ratio_bucket'] = bucket\n",
    "print (strategy_vector_data['train'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(strategy_vector_data, open('../../../data/negotiation_data/data/strategy_vector_data_FULL.pkl', 'wb'))\n",
    "pickle.dump(strategy_vector_data, open('../../data/negotiation_data/strategy_vector_data_FULL_Yiheng.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<price>_-0.2\n",
      "<price>_0.0\n",
      "<price>_0.4\n",
      "<price>_0.3\n",
      "<price>_-0.1\n",
      "<price>_-0.0\n",
      "<price>_-0.3\n",
      "<price>_0.6\n",
      "<price>_0.5\n",
      "<price>_-1.5\n",
      "<price>_0.7\n",
      "<price>_-0.6\n",
      "<price>_-2.0\n",
      "<price>_-1.2\n",
      "<price>_0.8\n",
      "<price>_-0.7\n",
      "<price>_2.0\n",
      "<price>_0.2\n",
      "<price>_-1.9\n",
      "<price>_-0.4\n",
      "<price>_1.1\n",
      "<price>_0.9\n",
      "<price>_1.0\n",
      "<price>_-0.5\n",
      "<price>_0.1\n",
      "<price>_1.8\n",
      "<price>_1.2\n",
      "<price>_-1.0\n",
      "<price>_1.4\n",
      "<price>_-0.8\n",
      "<price>_-0.9\n",
      "<price>_-1.1\n",
      "<price>_-1.3\n",
      "<price>_1.5\n",
      "<price>_-1.4\n",
      "<price>_1.6\n",
      "<price>_1.7\n",
      "<price>_1.3\n",
      "<price>_-1.7\n",
      "<price>_1.9\n",
      "<price>_-1.6\n",
      "<price>_-1.8\n"
     ]
    }
   ],
   "source": [
    "for w in strategy_vector_data['word2id']:\n",
    "    if '<price' in w:\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
